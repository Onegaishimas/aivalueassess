{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama\n"
     ]
    }
   ],
   "source": [
    "# Specify number of use cases to process or use \"All\" for the entire file\n",
    "num_to_process = \"3\" #input(\"Enter the number of use cases to process (or 'All' for all use cases): \").strip()\n",
    "\n",
    "# Set the input file path\n",
    "# input_file = \"artifact/ai_uc_inventory-dhs.xlsx\" \n",
    "input_file = \"artifact/2024_consolidated_ai_inventory_raw.xlsx\"\n",
    "\n",
    "# # OpenAI API \n",
    "# api_url = \"https://api.openai.com/v1\"\n",
    "# # load api key from .env_val file...syntax [OPENAI_API_KEY=\"your_api_key\"]\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# load_dotenv('.env_vals')\n",
    "# str_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# model_name=\"gpt-4\"\n",
    "# # Set the output file paths\n",
    "# output_file_json = \"artifact/ai_use_case_analysis.openai.json\"\n",
    "# output_file_jsonl = \"artifact/ai_use_case_analysis.openai.jsonl\"\n",
    "# output_file_json = \"artifact/global_ai_use_case_analysis.openai.json\"\n",
    "# output_file_jsonl = \"artifact/global_ai_use_case_analysis.openai.jsonl\"\n",
    "\n",
    "# Ollama API\n",
    "api_url = \"http://192.168.244.61:5500/v1\"\n",
    "str_api_key=\"ollama\"\n",
    "model_name=\"wizard-vicuna-uncensored:30b\"\n",
    "# Set the output file paths\n",
    "# output_file_json = \"artifact/dhs_ai_use_case_analysis.local.json\"\n",
    "# output_file_jsonl = \"artifact/dhs_ai_use_case_analysis.local.jsonl\"\n",
    "output_file_json = \"artifact/global_ai_use_case_analysis.local.json\"\n",
    "output_file_jsonl = \"artifact/global_ai_use_case_analysis.local.jsonl\"\n",
    "\n",
    "# Validate the API key\n",
    "print(str_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed. Results saved to artifact/global_ai_use_case_analysis.local.json and artifact/global_ai_use_case_analysis.local.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from openai import Client\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "client = Client(api_key=str_api_key,base_url=api_url)\n",
    "\n",
    "# Load the input XLSX dataset\n",
    "all_data = pd.read_excel(input_file)\n",
    "\n",
    "# Determine the data to process\n",
    "if num_to_process.lower() == \"all\":\n",
    "    data_to_process = all_data\n",
    "else:\n",
    "    try:\n",
    "        num_to_process = int(num_to_process)\n",
    "        data_to_process = all_data.head(num_to_process)\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number or 'All'.\")\n",
    "        exit()\n",
    "\n",
    "# List to hold the results\n",
    "results = []\n",
    "\n",
    "# Iterate through the selected use cases\n",
    "for index, row in data_to_process.iterrows():\n",
    "    usecase_id = row.get(\"Use Case ID\", \"Not provided\")\n",
    "    use_case_name = row.get(\"Use Case Name\", f\"Use Case {index + 1}\")\n",
    "    \n",
    "    if input_file == \"artifact/2024_consolidated_ai_inventory_raw.xlsx\":\n",
    "\n",
    "        agency = row.get(\"Agency\", \"Not provided\")\n",
    "        bureau_dept = row.get(\"Bureau\", \"Not provided\")\n",
    "        benefit_statement = row.get(\"What is the intended purpose and expected benefits of the AI?\", \"Not provided\")\n",
    "        system_outputs = row.get(\"Describe the AI systemâ€™s outputs.\", \"Not provided\")\n",
    "\n",
    "    else: # For the DHS AI Use Case Analysis file structure\n",
    "\n",
    "        agency = row.get(\"Agency\", \"Not provided\")\n",
    "        bureau_dept = row.get(\"Bureau / Department\", \"Not provided\")\n",
    "        benefit_statement = row.get(\"Summary of Use Case\", \"Not provided\") + \" \" + row.get(\"What is the intended purpose and expected benefits of the AI?\", \"Not provided\")\n",
    "        system_outputs = row.get(\"System Outputs\", \"Not provided\")\n",
    "\n",
    "    # Prepare the use case details\n",
    "    use_case_details = f\"\"\"\n",
    "- Use Case ID: {usecase_id}\n",
    "- Agency: {agency}\n",
    "- Bureau / Department: {bureau_dept}\n",
    "- Benefit Statement: {benefit_statement}\n",
    "- System Outputs: {system_outputs}\n",
    "\"\"\"\n",
    " \n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"\n",
    "As a helpful assistant, please analyze the following AI use case <use_case>:\n",
    "\n",
    "<use_case>\n",
    "**Details:**\n",
    "{use_case_details}\n",
    "</use_case>\n",
    "\n",
    "It will be very helpful if you will address these areas concisely:\n",
    "\n",
    "### **A. Named Entity Relationships**\n",
    "Extract entities from the Purpose Statement, Benefit Statement, and System Outputs:\n",
    "1. **PERSON**: Individuals or roles.\n",
    "2. **ORGANIZATION**: Agencies or entities.\n",
    "3. **LOCATION**: Places mentioned.\n",
    "4. **DATE**: Specific timeframes.\n",
    "\n",
    "### **B. Dependency Parsing and Analysis**\n",
    "1. Identify grammatical relationships and dependency labels (e.g., subject, object).\n",
    "2. Highlight key sentence structures reflecting goals or constraints.\n",
    "3. Note ambiguities and incomplete dependencies.\n",
    "\n",
    "### **C. Functional and Non-Functional Requirements**\n",
    "From the use case and analyses:\n",
    "- **Functional Requirements**: Actions the system must perform (e.g., data processing).\n",
    "- **Non-Functional Requirements**: Constraints like performance or scalability.\n",
    "Structure:\n",
    "- **ID**: Unique identifier.\n",
    "- **Type**: Functional or Non-Functional.\n",
    "- **Description**: Requirement summary.\n",
    "- **Rationale**: Why it matters.\n",
    "- **Dependencies**: Links to related components.\n",
    "\n",
    "### **D. Value Categorization**\n",
    "Classify as one:\n",
    "1. **Efficiency Amplifier**: Use cases that streamline existing processes, reduce resource consumption, or improve speed and accuracy within existing workflows.\n",
    "2. **Capability Enhancer**: Use cases that introduce new capabilities, expand operational boundaries, or enable tasks previously constrained by resource or technical limitations.\n",
    "3. **Breakthrough Enabler**: Use cases that achieve novel outcomes, redefine operational paradigms, or transcend traditional limitations entirely.\n",
    "\n",
    "Justify based on purpose, outputs, and context.\n",
    "\n",
    "### **E. Operational Impact and Transformation**\n",
    "1. **Operational Impact**: Improvements in efficiency or capability.\n",
    "2. **Transformation**: Changes to workflows or overcoming limitations.\n",
    "\n",
    "### **F. Value Metrics**\n",
    "Measure value through:\n",
    "- Operational metrics (e.g., time saved).\n",
    "- Organizational benefits (e.g., cost reduction).\n",
    "- Societal impacts (e.g., improved security).\n",
    "\n",
    "Provide responses with clarity and focus, ensuring the analysis aligns with the data available in the AI use case. Use explicit references to information from the Purpose Statement, Benefit Statement, and System Outputs to ground conclusions. Where data is missing or ambiguous, make reasonable inferences based on established patterns in similar use cases, and flag areas requiring further clarification for completeness.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Submit the prompt to OpenAI API using the ChatCompletion interface\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,  #\"gpt-4\",  # Use \"gpt-3.5-turbo\" if preferred\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant who is an expert at analyzing proposals for AI use cases.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=6000\n",
    "        )\n",
    "\n",
    "        # Extract the response text\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Append the result to the list\n",
    "        results.append({\n",
    "            \"Use Case ID\": usecase_id,\n",
    "            \"Agency\": agency,\n",
    "            \"Bureau / Department\": bureau_dept,\n",
    "            \"Use Case Name\": use_case_name,\n",
    "            \"Benefit Statement\": benefit_statement,\n",
    "            \"System Outputs\": system_outputs,\n",
    "            # \"Prompt\": prompt, # Commented out to avoid saving the prompt in the JSON file\n",
    "            \"Response\": response_text\n",
    "        })\n",
    "\n",
    "        # Write the result to a JSON Lines file\n",
    "        with open(output_file_jsonl, mode=\"a\", encoding=\"utf-8\") as file:\n",
    "            json.dump({\n",
    "                \"Use Case ID\": usecase_id,\n",
    "                \"Agency\": agency,\n",
    "                \"Bureau / Department\": bureau_dept,\n",
    "                \"Use Case Name\": use_case_name,\n",
    "                \"Benefit Statement\": benefit_statement,\n",
    "                \"System Outputs\": system_outputs,\n",
    "                # \"Prompt\": prompt, # Commented out to avoid saving the prompt in the JSON file\n",
    "                \"Response\": response_text\n",
    "            }, file)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt for use case '{use_case_name}': {e}\")\n",
    "        print(f\"Detailed error: {str(e)}\")\n",
    "        print(f\"API Base URL: {client.base_url}\")\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open(output_file_json, mode=\"a\", encoding=\"utf-8\") as file:\n",
    "    json.dump(results, file, indent=4)\n",
    "\n",
    "print(f\"Analysis completed. Results saved to {output_file_json} and {output_file_jsonl}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
